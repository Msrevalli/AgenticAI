# **ğŸš€ Understanding Prompt Chaining in AI Workflows**
### **ğŸ“Œ What is Prompt Chaining?**
**Prompt chaining** is a technique where **multiple prompts** are **linked together in a structured sequence** to refine, enhance, or guide AI-generated responses.

Instead of providing a **single, complex prompt**, prompt chaining **breaks down a task into smaller steps**, where **each step builds upon the previous one**.

### **ğŸ”¹ Benefits of Prompt Chaining**
âœ… **Better Accuracy** â€“ AI **refines responses iteratively**, reducing hallucinations.  
âœ… **Task Breakdown** â€“ Complex problems **become manageable**, improving AI output.  
âœ… **Controlled AI Responses** â€“ Each step **guides AI** to stay on topic.  
âœ… **Memory Handling** â€“ AI **remembers previous context** for multi-turn interactions.  

---

## **ğŸ“Œ How Prompt Chaining Works in LangGraph?**
LangGraph uses **graph-based execution** where **nodes (functions) are connected as a sequence**.  
Unlike **linear LangChain chains**, LangGraph allows:
- **More flexible chaining** (e.g., loops, conditional branching).
- **Parallel execution of prompts** (instead of just sequential processing).
- **State tracking** for **memory & multi-step workflows**.

### **ğŸ”¹ Steps to Use Prompt Chaining in LangGraph**
1. **Define State** â†’ Store and track **conversation context**.  
2. **Create Nodes** â†’ Each **prompt step** runs as a **separate function**.  
3. **Define Edges** â†’ Link **nodes together** to form a **chain-like workflow**.  
4. **Compile & Execute** â†’ The graph executes **each step sequentially**.

---

## **ğŸš€ Example: Prompt Chaining for AI Content Refinement**
We will build a **3-step LangGraph-based prompt chain**:
1ï¸âƒ£ **Extract Keywords** â€“ Identify main concepts from user input.  
2ï¸âƒ£ **Generate Summary** â€“ Use extracted keywords to create a short summary.  
3ï¸âƒ£ **Generate AI-Enhanced Response** â€“ Convert the summary into a **detailed response**.

### **ğŸ”¹ Execution Flow:**
```
START â†’ Extract Keywords â†’ Generate Summary â†’ AI-Enhanced Response â†’ END
```

---

### **ğŸ“Œ Full Code for Prompt Chaining in LangGraph**
```python
# ğŸ“Œ Import Required Libraries
import os
from dotenv import load_dotenv
from typing_extensions import TypedDict
from typing import Annotated
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# âœ… Load Environment Variables (for OpenAI API Key)
load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# âœ… Initialize LLM (GPT-4)
llm = ChatOpenAI(model="gpt-4", temperature=0)

# âœ… Define AI State (Memory for Workflow)
class AIState(TypedDict):
    messages: Annotated[list, add_messages]

# âœ… Step 1: Extract Keywords Prompt
extract_keywords_prompt = PromptTemplate(
    input_variables=["text"],
    template="Extract the main keywords from the following text:\n{text}"
)
extract_chain = LLMChain(llm=llm, prompt=extract_keywords_prompt)

def extract_keywords(state: AIState):
    """Extracts keywords from user input"""
    keywords = extract_chain.run(state["messages"][-1])  # Last message contains user input
    return {"messages": state["messages"] + [keywords]}  # Adds keywords to state

# âœ… Step 2: Generate Summary Prompt
summary_prompt = PromptTemplate(
    input_variables=["keywords"],
    template="Using these keywords: {keywords}, generate a concise summary."
)
summary_chain = LLMChain(llm=llm, prompt=summary_prompt)

def generate_summary(state: AIState):
    """Generates a summary using extracted keywords"""
    summary = summary_chain.run(state["messages"][-1])  # Uses extracted keywords
    return {"messages": state["messages"] + [summary]}  # Adds summary to state

# âœ… Step 3: Generate AI-Enhanced Response
final_prompt = PromptTemplate(
    input_variables=["summary"],
    template="Use this summary: {summary}, and generate a detailed AI-enhanced response."
)
final_chain = LLMChain(llm=llm, prompt=final_prompt)

def enhanced_response(state: AIState):
    """Enhances the summary into a full AI-generated response"""
    response = final_chain.run(state["messages"][-1])  # Uses summary
    return {"messages": state["messages"] + [response]}  # Adds final response

# âœ… Build LangGraph Workflow
workflow = StateGraph(AIState)

# â¤ Add Nodes
workflow.add_node("extract_keywords", extract_keywords)
workflow.add_node("generate_summary", generate_summary)
workflow.add_node("enhanced_response", enhanced_response)

# â¤ Define Execution Flow
workflow.add_edge(START, "extract_keywords")  # Start â†’ Extract Keywords
workflow.add_edge("extract_keywords", "generate_summary")  # Keywords â†’ Summary
workflow.add_edge("generate_summary", "enhanced_response")  # Summary â†’ Final Response
workflow.add_edge("enhanced_response", END)  # Final Response â†’ End

# âœ… Compile the Graph
graph = workflow.compile()

# âœ… Function to Run the Workflow
def process_input(user_input: str):
    """
    Runs the AI workflow with prompt chaining for a given input.
    """
    state = {"messages": [user_input]}  # Initialize chat state
    response = graph.invoke(state)

    for message in response["messages"]:
        print("ğŸš€ AI Response:", message)

# âœ… Run Prompt Chaining AI Chatbot
if __name__ == "__main__":
    print("\nğŸ¤– AI Chatbot with Prompt Chaining (LangGraph) | Type 'exit' to quit\n")

    while True:
        try:
            user_input = input("User: ")
            if user_input.lower() in ["quit", "exit", "q"]:
                print("Goodbye! ğŸ‘‹")
                break

            process_input(user_input)

        except Exception as e:
            print("Error:", str(e))
            break
```

---

## **ğŸ“Œ How This LangGraph Workflow Works**
| **Step** | **Action** | **Example Output** |
|---------|-----------|------------------|
| **1ï¸âƒ£ Extract Keywords** | AI extracts **key terms** from input | `"LangChain, AI, workflow"` |
| **2ï¸âƒ£ Generate Summary** | AI creates a **short summary** using keywords | `"LangChain helps build AI workflows."` |
| **3ï¸âƒ£ Enhance Response** | AI **expands** the summary into a detailed response | `"LangChain is a framework for structuring AI workflows using LLMs."` |

âœ” **Each step refines the response for better accuracy!** ğŸš€  

---

## **ğŸ“Œ Expected Output**
```plaintext
ğŸ¤– AI Chatbot with Prompt Chaining (LangGraph) | Type 'exit' to quit

User: What is LangChain?
ğŸš€ AI Response: LangChain, AI, LLM, framework
ğŸš€ AI Response: LangChain is an AI framework for building LLM applications.
ğŸš€ AI Response: LangChain simplifies AI integration by providing structured workflows for LLM-powered applications.
```
âœ” **AI automatically sequences prompt execution!** ğŸ‰  

---

## **ğŸ“Œ When to Use Prompt Chaining in LangGraph?**
| **Use Case** | **Why Use It?** |
|-------------|------------------|
| **Complex AI Workflows** | Break down tasks into **smaller, manageable steps**. |
| **Multi-Step Reasoning** | AI **refines, verifies, and enhances** responses. |
| **Text Summarization & Analysis** | Extract key insights before **generating answers**. |
| **Legal & Finance Reports** | Ensure AI **processes facts before making conclusions**. |
| **Customer Support Chatbots** | Guide AI to **ask clarifying questions before responding**. |

---

# **ğŸš€ Final Thoughts**
ğŸ”¹ **Prompt chaining in LangGraph** enables **structured, iterative AI processing**.  
ğŸ”¹ **Unlike LangChain chains**, LangGraph allows **conditional logic, loops, and multi-agent workflows**.  
ğŸ”¹ **Useful for summarization, report generation, and advanced chatbot logic.**

