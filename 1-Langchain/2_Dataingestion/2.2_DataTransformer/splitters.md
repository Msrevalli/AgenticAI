# **ğŸ“Œ Text Splitters in LangChain**
Text splitters in **LangChain** are used to **break large documents into smaller chunks** for **efficient retrieval, storage, and processing** in **AI applications, RAG pipelines, and vector databases**.

---

## **ğŸš€ Why Use Text Splitters?**
âœ” **Improves Retrieval** â€“ Smaller chunks **enhance search accuracy** in AI-powered applications.  
âœ” **Optimizes LLM Processing** â€“ Helps **stay within token limits** for LLMs.  
âœ” **Reduces Context Window Issues** â€“ Ensures AI gets **relevant chunks** instead of entire documents.  
âœ” **Enhances RAG Performance** â€“ Enables **semantic search & question-answering**.  

---

## **ğŸ›  Types of Text Splitters in LangChain**
| **Splitter** | **Best For** | **How It Splits** |
|-------------|-------------|------------------|
| **RecursiveCharacterTextSplitter** | General-purpose AI applications | Splits at the largest possible **natural boundary** (paragraph â†’ sentence â†’ word) |
| **CharacterTextSplitter** | Basic text splitting | Splits at a specific **character** (e.g., `\n`, `.`, ` `) |
| **TokenTextSplitter** | LLMs like GPT, Claude | Splits text based on **token count** |
| **NLTKTextSplitter** | NLP-based AI models | Uses **NLTK sentence tokenization** |
| **MarkdownTextSplitter** | Processing Markdown files | Splits **headers, paragraphs, lists, and code blocks** |
| **HTMLHeaderTextSplitter** | Extracting web content | Splits HTML using **headers (H1, H2, etc.)** |
| **LanguageTextSplitter** | Code analysis | Splits **Python, Java, C++ code** into logical sections |
| **SentenceTransformersTextSplitter** | Semantic chunking | Uses **pre-trained models for intelligent splitting** |

---

## **1ï¸âƒ£ Recursive Character Splitter (Recommended)**
ğŸ”¹ **Best for:** **General-purpose document chunking**  
ğŸ”¹ **How it works:** **Splits at natural boundaries** (paragraph â†’ sentence â†’ word).  

### **ğŸ“Œ Example**
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

text = "LangChain makes AI applications powerful. It supports retrieval, agents, and chains."

splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)
chunks = splitter.split_text(text)

print(chunks)
```
âœ” **Best for:** AI-powered **search, summarization, and chatbots**.

---

## **2ï¸âƒ£ Character Text Splitter**
ğŸ”¹ **Best for:** **Splitting at a specific character** (`\n`, `.`, `,`)  
ğŸ”¹ **How it works:** Splits **whenever a character limit is reached**.  

### **ğŸ“Œ Example**
```python
from langchain.text_splitter import CharacterTextSplitter

splitter = CharacterTextSplitter(separator="\n\n", chunk_size=100, chunk_overlap=10)
chunks = splitter.split_text("Paragraph 1...\n\nParagraph 2...\n\nParagraph 3...")
print(chunks)
```
âœ” **Best for:** **Simple text processing**.

---

## **3ï¸âƒ£ Token Text Splitter**
ğŸ”¹ **Best for:** **LLMs like GPT-4, Claude, and Mistral**  
ğŸ”¹ **How it works:** Splits **based on token count** instead of characters.  

### **ğŸ“Œ Example**
```python
from langchain.text_splitter import TokenTextSplitter

splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=10)
chunks = splitter.split_text("OpenAI's GPT models use tokens, not words.")
print(chunks)
```
âœ” **Best for:** **GPT & LLM-based applications**.

---

## **4ï¸âƒ£ NLTK Sentence Splitter**
ğŸ”¹ **Best for:** **Splitting text at sentence boundaries**  
ğŸ”¹ **How it works:** Uses **NLTKâ€™s sentence tokenizer**.  

### **ğŸ“Œ Example**
```python
from langchain.text_splitter import NLTKTextSplitter

splitter = NLTKTextSplitter()
chunks = splitter.split_text("Sentence one. Sentence two! Sentence three?")
print(chunks)
```
âœ” **Best for:** **Natural Language Processing (NLP) tasks**.

---

## **5ï¸âƒ£ Markdown Text Splitter**
ğŸ”¹ **Best for:** **Processing Markdown files**  
ğŸ”¹ **How it works:** Splits **headers, code blocks, lists, and paragraphs**.  

### **ğŸ“Œ Example**
```python
from langchain.text_splitter import MarkdownTextSplitter

text = "# Header 1\nContent under header.\n## Header 2\nMore content."
splitter = MarkdownTextSplitter()
chunks = splitter.split_text(text)
print(chunks)
```
âœ” **Best for:** **AI-powered document processing**.

---

## **6ï¸âƒ£ HTML Header Splitter**
ğŸ”¹ **Best for:** **Extracting structured content from web pages**  
ğŸ”¹ **How it works:** Splits **at HTML headers (H1, H2, H3, etc.)**.  

### **ğŸ“Œ Example**
```python
from langchain.text_splitter import HTMLHeaderTextSplitter

html_text = "<h1>Main Title</h1><p>Intro paragraph.</p><h2>Subsection</h2><p>More content.</p>"
splitter = HTMLHeaderTextSplitter(headers_to_split_on=["h1", "h2"])
chunks = splitter.split_text(html_text)
print(chunks)
```
âœ” **Best for:** **Processing scraped web content**.

---

## **7ï¸âƒ£ Code (Language) Splitter**
ğŸ”¹ **Best for:** **Splitting programming code into functions, classes, and logic blocks**.  
ğŸ”¹ **How it works:** Splits **Python, Java, C++ code** using language rules.  

### **ğŸ“Œ Example**
```python
from langchain.text_splitter import Language, LanguageTextSplitter

code = "def function():\n    print('Hello World')\n\nclass MyClass:\n    pass"
splitter = LanguageTextSplitter(language=Language.PYTHON, chunk_size=50, chunk_overlap=10)
chunks = splitter.split_text(code)
print(chunks)
```
âœ” **Best for:** **AI-powered code analysis & documentation**.

---

## **8ï¸âƒ£ Sentence Transformers Splitter**
ğŸ”¹ **Best for:** **Semantic chunking based on sentence meaning**  
ğŸ”¹ **How it works:** Uses **pre-trained sentence transformers** to split intelligently.  

### **ğŸ“Œ Example**
```python
from langchain.text_splitter import SentenceTransformersTextSplitter

splitter = SentenceTransformersTextSplitter(model_name="sentence-transformers/all-MiniLM-L6-v2")
chunks = splitter.split_text("Machine Learning is transforming industries. AI is growing fast.")
print(chunks)
```
âœ” **Best for:** **Semantic AI applications**.

---

## **ğŸš€ Which LangChain Splitter Should You Use?**
| **Splitter** | **Best For** |
|-------------|-------------|
| **RecursiveCharacterTextSplitter** | **General-purpose document splitting** |
| **CharacterTextSplitter** | **Simple text-based chunking** |
| **TokenTextSplitter** | **GPT-4, Claude, LLMs (token-based chunking)** |
| **NLTKTextSplitter** | **NLP-based sentence tokenization** |
| **MarkdownTextSplitter** | **Processing Markdown files** |
| **HTMLHeaderTextSplitter** | **Extracting structured content from web pages** |
| **LanguageTextSplitter** | **Splitting Python, Java, and C++ code** |
| **SentenceTransformersTextSplitter** | **Semantic-aware chunking** |

---

